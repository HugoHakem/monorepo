#+title: Readme (draft)
:PROPERTIES:
:ID:       e6d67cd0-e380-4e02-bd03-c48dd93647a7
:END:
#+roam_tags: reference
Structrure idea for broad monorepo that integrates tools used by multiple members of the imaging platform's data team.

* Root
** Technical documentation
*** Structure explanation
 Explaining the structure of the monorepo
 Repo organisation
*** User docs
**** Tutorials
*** Dev docs
**** General contribution guidelines
***** Getting started
***** Style (e.g., black, flake8)
***** Testing recommendations (pytest, CI)
***** Requests for change
**** Coding suggestions
- Numpy vectorisation
- General anti-patterns, so we can avoid them
- Dealing with big datasets
** Data Munging (Shell + Python)
Tools/scripts to convert one data format to another one, or to filter and do intermediate (optional) processing steps
** Workflows (Python Notebooks)
*** "Standard" workflow
Simple straightforwars
*** Legacy
Place profile recipes and other workflows here for archiving and reference purposes
*** Decision-making repos
Compendium of links to the repositories where decisions were made.
*** Useful shell scripts
- Edit and move data across computers
- Move to/from dgx
- Download entire dataset
** Packages (Python)
- env.yaml (to ensure compatibility and avoid hard conficts)
*** Copairs
*** mAP calculation
*** PyCytominer parallel branch?
Alternative is git patch
*** Visualisation
Standardise our visualisation interfaces
*** JUMP toolbox
**** Metadata addition
Function(s) to add metadata that is needed for data mining workflows to run
**** Broad_babel
Python library to fetch basic metadata (sample names, control type) from any of the JUMP data sources
**** jump_drug_target_interactions
Fetch annotations for drug-target-interactions metadata, obtained from https://github.com/jump-cellpainting/compound-annotator/tree/dti_annotations, but removing all the unrelated commits.
*** IO tools Python
**** AWS interfaces
Get our data from AWS
**** Data compression/conversion
